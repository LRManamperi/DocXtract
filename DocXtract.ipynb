{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q28SJqarsgGo",
        "outputId": "0ed1bc86-7a30-40ac-921e-5a2a9817cfa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.6 pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "pip install PyMuPDF opencv-python numpy pandas pillow pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dHkKYi-yUzA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple, Optional, Union\n",
        "from enum import Enum\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQEDKiUkyYIv"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CORE DATA STRUCTURES\n",
        "# ============================================================================\n",
        "\n",
        "class ElementType(Enum):\n",
        "    \"\"\"Types of elements that can be extracted\"\"\"\n",
        "    TABLE = \"table\"\n",
        "    LINE_CHART = \"line_chart\"\n",
        "    BAR_CHART = \"bar_chart\"\n",
        "    PIE_CHART = \"pie_chart\"\n",
        "    SCATTER_PLOT = \"scatter_plot\"\n",
        "    HEATMAP = \"heatmap\"\n",
        "    UNKNOWN = \"unknown\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class BoundingBox:\n",
        "    \"\"\"Bounding box for extracted elements\"\"\"\n",
        "    x1: float\n",
        "    y1: float\n",
        "    x2: float\n",
        "    y2: float\n",
        "\n",
        "    @property\n",
        "    def width(self) -> float:\n",
        "        return self.x2 - self.x1\n",
        "\n",
        "    @property\n",
        "    def height(self) -> float:\n",
        "        return self.y2 - self.y1\n",
        "\n",
        "    @property\n",
        "    def area(self) -> float:\n",
        "        return self.width * self.height\n",
        "\n",
        "    @property\n",
        "    def aspect_ratio(self) -> float:\n",
        "        return self.width / self.height if self.height > 0 else 0\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        return {\n",
        "            'x1': self.x1, 'y1': self.y1,\n",
        "            'x2': self.x2, 'y2': self.y2,\n",
        "            'width': self.width, 'height': self.height\n",
        "        }\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Cell:\n",
        "    \"\"\"Individual cell in a table\"\"\"\n",
        "    text: str\n",
        "    bbox: BoundingBox\n",
        "    row: int\n",
        "    col: int\n",
        "    rowspan: int = 1\n",
        "    colspan: int = 1\n",
        "    confidence: float = 1.0\n",
        "\n",
        "\n",
        "class Table:\n",
        "    \"\"\"\n",
        "    Represents an extracted table with rich metadata\n",
        "    Similar to Camelot's Table object\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data: List[List[str]], bbox: BoundingBox,\n",
        "                 page: int, accuracy: float = 0.0):\n",
        "        self.data = data\n",
        "        self.bbox = bbox\n",
        "        self.page = page\n",
        "        self.accuracy = accuracy\n",
        "        self._df = None\n",
        "        self.cells = []\n",
        "        self.parsing_report = {}\n",
        "\n",
        "    @property\n",
        "    def df(self) -> pd.DataFrame:\n",
        "        \"\"\"Convert table to pandas DataFrame\"\"\"\n",
        "        if self._df is None:\n",
        "            if not self.data:\n",
        "                self._df = pd.DataFrame()\n",
        "            else:\n",
        "                # First row as header\n",
        "                if len(self.data) > 1:\n",
        "                    self._df = pd.DataFrame(self.data[1:], columns=self.data[0])\n",
        "                else:\n",
        "                    self._df = pd.DataFrame(self.data)\n",
        "        return self._df\n",
        "\n",
        "    @property\n",
        "    def shape(self) -> Tuple[int, int]:\n",
        "        \"\"\"Return (rows, cols)\"\"\"\n",
        "        if not self.data:\n",
        "            return (0, 0)\n",
        "        return (len(self.data), len(self.data[0]) if self.data else 0)\n",
        "\n",
        "    def to_csv(self, path: str):\n",
        "        \"\"\"Export table to CSV\"\"\"\n",
        "        self.df.to_csv(path, index=False)\n",
        "\n",
        "    def to_excel(self, path: str):\n",
        "        \"\"\"Export table to Excel\"\"\"\n",
        "        self.df.to_excel(path, index=False)\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        \"\"\"Export table metadata\"\"\"\n",
        "        return {\n",
        "            'page': self.page,\n",
        "            'bbox': self.bbox.to_dict(),\n",
        "            'shape': self.shape,\n",
        "            'accuracy': self.accuracy,\n",
        "            'data': self.data\n",
        "        }\n",
        "\n",
        "\n",
        "class Graph:\n",
        "    \"\"\"Represents an extracted graph/chart\"\"\"\n",
        "\n",
        "    def __init__(self, image: np.ndarray, bbox: BoundingBox,\n",
        "                 page: int, graph_type: ElementType, confidence: float = 0.0):\n",
        "        self.image = image\n",
        "        self.bbox = bbox\n",
        "        self.page = page\n",
        "        self.graph_type = graph_type\n",
        "        self.confidence = confidence\n",
        "        self.metadata = {}\n",
        "        self.extracted_data = None\n",
        "\n",
        "    def save_image(self, path: str):\n",
        "        \"\"\"Save graph image\"\"\"\n",
        "        cv2.imwrite(path, self.image)\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        \"\"\"Export graph metadata\"\"\"\n",
        "        return {\n",
        "            'page': self.page,\n",
        "            'type': self.graph_type.value,\n",
        "            'bbox': self.bbox.to_dict(),\n",
        "            'confidence': self.confidence,\n",
        "            'metadata': self.metadata\n",
        "        }\n",
        "\n",
        "\n",
        "class ExtractionResult:\n",
        "    \"\"\"Container for all extracted elements from a PDF\"\"\"\n",
        "\n",
        "    def __init__(self, pdf_path: str):\n",
        "        self.pdf_path = pdf_path\n",
        "        self.tables: List[Table] = []\n",
        "        self.graphs: List[Graph] = []\n",
        "        self.n_pages = 0\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"ExtractionResult(tables={len(self.tables)}, graphs={len(self.graphs)})\"\n",
        "\n",
        "    def filter_by_page(self, page: int):\n",
        "        \"\"\"Get elements from specific page\"\"\"\n",
        "        return ExtractionResult._filter(self, page)\n",
        "\n",
        "    @staticmethod\n",
        "    def _filter(result, page):\n",
        "        filtered = ExtractionResult(result.pdf_path)\n",
        "        filtered.tables = [t for t in result.tables if t.page == page]\n",
        "        filtered.graphs = [g for g in result.graphs if g.page == page]\n",
        "        filtered.n_pages = result.n_pages\n",
        "        return filtered\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm2R5lPwyhwk"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ABSTRACT BASE CLASSES FOR EXTRACTORS\n",
        "# ============================================================================\n",
        "\n",
        "class BaseDetector(ABC):\n",
        "    \"\"\"Base class for element detection strategies\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def detect(self, page_image: np.ndarray, page_num: int) -> List[BoundingBox]:\n",
        "        \"\"\"Detect elements and return bounding boxes\"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class BaseParser(ABC):\n",
        "    \"\"\"Base class for parsing detected elements\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def parse(self, region: np.ndarray, bbox: BoundingBox) -> Union[Table, Graph]:\n",
        "        \"\"\"Parse a detected region into structured data\"\"\"\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnFDciCJykg6"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# TABLE DETECTION STRATEGIES\n",
        "# ============================================================================\n",
        "\n",
        "class LineBasedTableDetector(BaseDetector):\n",
        "    \"\"\"\n",
        "    Detect tables based on line structures (borders)\n",
        "    Similar to Camelot's lattice mode\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, min_lines: int = 4, line_scale: int = 15):\n",
        "        self.min_lines = min_lines\n",
        "        self.line_scale = line_scale\n",
        "\n",
        "    def detect(self, page_image: np.ndarray, page_num: int) -> List[BoundingBox]:\n",
        "        \"\"\"Detect tables using line detection\"\"\"\n",
        "        gray = cv2.cvtColor(page_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Adaptive threshold\n",
        "        thresh = cv2.adaptiveThreshold(\n",
        "            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "            cv2.THRESH_BINARY_INV, 11, 2\n",
        "        )\n",
        "\n",
        "        # Detect horizontal and vertical lines\n",
        "        horizontal_kernel = cv2.getStructuringElement(\n",
        "            cv2.MORPH_RECT, (page_image.shape[1]//self.line_scale, 1)\n",
        "        )\n",
        "        vertical_kernel = cv2.getStructuringElement(\n",
        "            cv2.MORPH_RECT, (1, page_image.shape[0]//self.line_scale)\n",
        "        )\n",
        "\n",
        "        h_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel)\n",
        "        v_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel)\n",
        "\n",
        "        # Combine lines\n",
        "        table_mask = cv2.add(h_lines, v_lines)\n",
        "\n",
        "        # Find contours\n",
        "        contours, _ = cv2.findContours(\n",
        "            table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        "        )\n",
        "\n",
        "        bboxes = []\n",
        "        for contour in contours:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "            # Filter by size and aspect ratio\n",
        "            if w > 100 and h > 100 and 0.1 < (w/h) < 10:\n",
        "                bboxes.append(BoundingBox(x, y, x+w, y+h))\n",
        "\n",
        "        return bboxes\n",
        "\n",
        "\n",
        "class TextClusterTableDetector(BaseDetector):\n",
        "    \"\"\"\n",
        "    Detect tables based on text alignment patterns\n",
        "    Similar to Camelot's stream mode\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, row_tol: float = 2, col_tol: float = 5):\n",
        "        self.row_tol = row_tol\n",
        "        self.col_tol = col_tol\n",
        "\n",
        "    def detect(self, page_image: np.ndarray, page_num: int) -> List[BoundingBox]:\n",
        "        \"\"\"Detect tables using text clustering\"\"\"\n",
        "        # This would use PyMuPDF text extraction\n",
        "        # Simplified version here\n",
        "        gray = cv2.cvtColor(page_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Detect text regions\n",
        "        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "        # Find connected components (text blocks)\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Cluster nearby text blocks\n",
        "        text_blocks = []\n",
        "        for contour in contours:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            if w > 10 and h > 10:  # Minimum text size\n",
        "                text_blocks.append((x, y, w, h))\n",
        "\n",
        "        # Group into table regions (simplified)\n",
        "        bboxes = self._cluster_text_blocks(text_blocks)\n",
        "        return bboxes\n",
        "\n",
        "    def _cluster_text_blocks(self, blocks: List[Tuple]) -> List[BoundingBox]:\n",
        "        \"\"\"Cluster text blocks into table regions\"\"\"\n",
        "        if not blocks:\n",
        "            return []\n",
        "\n",
        "        # Sort by y-coordinate\n",
        "        blocks = sorted(blocks, key=lambda b: b[1])\n",
        "\n",
        "        # Group into rows\n",
        "        rows = []\n",
        "        current_row = [blocks[0]]\n",
        "\n",
        "        for block in blocks[1:]:\n",
        "            if abs(block[1] - current_row[-1][1]) < self.row_tol:\n",
        "                current_row.append(block)\n",
        "            else:\n",
        "                rows.append(current_row)\n",
        "                current_row = [block]\n",
        "        rows.append(current_row)\n",
        "\n",
        "        # Find rectangular table regions\n",
        "        bboxes = []\n",
        "        if len(rows) >= 2:\n",
        "            x_min = min(b[0] for row in rows for b in row)\n",
        "            y_min = min(b[1] for row in rows for b in row)\n",
        "            x_max = max(b[0] + b[2] for row in rows for b in row)\n",
        "            y_max = max(b[1] + b[3] for row in rows for b in row)\n",
        "\n",
        "            bboxes.append(BoundingBox(x_min, y_min, x_max, y_max))\n",
        "\n",
        "        return bboxes\n",
        "\n",
        "\n",
        "class MLTableDetector(BaseDetector):\n",
        "    \"\"\"\n",
        "    ML-based table detection\n",
        "    Can be extended with custom models (YOLO, Faster R-CNN, etc.)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_path: Optional[str] = None, confidence: float = 0.5):\n",
        "        self.model_path = model_path\n",
        "        self.confidence = confidence\n",
        "        self.model = None\n",
        "\n",
        "        # Load model if provided\n",
        "        if model_path:\n",
        "            self._load_model()\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load custom ML model\"\"\"\n",
        "        # Placeholder for custom model loading\n",
        "        # Could use TensorFlow, PyTorch, or ONNX\n",
        "        pass\n",
        "\n",
        "    def detect(self, page_image: np.ndarray, page_num: int) -> List[BoundingBox]:\n",
        "        \"\"\"Detect tables using ML model\"\"\"\n",
        "        if self.model is None:\n",
        "            return []\n",
        "\n",
        "        # Run inference\n",
        "        # This is a placeholder - implement based on your model\n",
        "        predictions = []\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9l_06SAyuZB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# TABLE PARSING STRATEGIES\n",
        "# ============================================================================\n",
        "\n",
        "class GridBasedTableParser(BaseParser):\n",
        "    \"\"\"Parse tables by detecting grid structure\"\"\"\n",
        "\n",
        "    def parse(self, region: np.ndarray, bbox: BoundingBox) -> Table:\n",
        "        \"\"\"Parse table region into structured data\"\"\"\n",
        "        gray = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Detect lines\n",
        "        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
        "        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100,\n",
        "                                minLineLength=50, maxLineGap=10)\n",
        "\n",
        "        if lines is None:\n",
        "            return Table([], bbox, 0, 0.0)\n",
        "\n",
        "        # Separate horizontal and vertical lines\n",
        "        h_lines = []\n",
        "        v_lines = []\n",
        "\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)\n",
        "\n",
        "            if angle < 10 or angle > 170:  # Horizontal\n",
        "                h_lines.append(y1)\n",
        "            elif 80 < angle < 100:  # Vertical\n",
        "                v_lines.append(x1)\n",
        "\n",
        "        # Remove duplicates and sort\n",
        "        h_lines = sorted(list(set(h_lines)))\n",
        "        v_lines = sorted(list(set(v_lines)))\n",
        "\n",
        "        # Extract cells using OCR\n",
        "        cells = self._extract_cells(region, h_lines, v_lines)\n",
        "\n",
        "        # Convert to 2D array\n",
        "        data = self._cells_to_array(cells)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = self._calculate_accuracy(len(h_lines), len(v_lines), len(cells))\n",
        "\n",
        "        return Table(data, bbox, 0, accuracy)\n",
        "\n",
        "    def _extract_cells(self, image: np.ndarray, h_lines: List, v_lines: List) -> List[Cell]:\n",
        "        \"\"\"Extract text from grid cells using OCR\"\"\"\n",
        "        cells = []\n",
        "\n",
        "        try:\n",
        "            import pytesseract\n",
        "\n",
        "            for i in range(len(h_lines) - 1):\n",
        "                for j in range(len(v_lines) - 1):\n",
        "                    y1, y2 = h_lines[i], h_lines[i+1]\n",
        "                    x1, x2 = v_lines[j], v_lines[j+1]\n",
        "\n",
        "                    cell_img = image[y1:y2, x1:x2]\n",
        "                    text = pytesseract.image_to_string(cell_img).strip()\n",
        "\n",
        "                    cell = Cell(\n",
        "                        text=text,\n",
        "                        bbox=BoundingBox(x1, y1, x2, y2),\n",
        "                        row=i,\n",
        "                        col=j\n",
        "                    )\n",
        "                    cells.append(cell)\n",
        "        except ImportError:\n",
        "            pass  # OCR not available\n",
        "\n",
        "        return cells\n",
        "\n",
        "    def _cells_to_array(self, cells: List[Cell]) -> List[List[str]]:\n",
        "        \"\"\"Convert cells to 2D array\"\"\"\n",
        "        if not cells:\n",
        "            return []\n",
        "\n",
        "        max_row = max(c.row for c in cells) + 1\n",
        "        max_col = max(c.col for c in cells) + 1\n",
        "\n",
        "        data = [[\"\" for _ in range(max_col)] for _ in range(max_row)]\n",
        "\n",
        "        for cell in cells:\n",
        "            data[cell.row][cell.col] = cell.text\n",
        "\n",
        "        return data\n",
        "\n",
        "    def _calculate_accuracy(self, n_h_lines: int, n_v_lines: int, n_cells: int) -> float:\n",
        "        \"\"\"Calculate parsing accuracy score\"\"\"\n",
        "        expected_cells = (n_h_lines - 1) * (n_v_lines - 1)\n",
        "        if expected_cells == 0:\n",
        "            return 0.0\n",
        "        return min(100.0, (n_cells / expected_cells) * 100)\n",
        "\n",
        "\n",
        "class TextBasedTableParser(BaseParser):\n",
        "    \"\"\"Parse tables using text position analysis\"\"\"\n",
        "\n",
        "    def parse(self, region: np.ndarray, bbox: BoundingBox) -> Table:\n",
        "        \"\"\"Parse using text extraction and alignment\"\"\"\n",
        "        # This would use PyMuPDF's text extraction with position info\n",
        "        # Simplified implementation\n",
        "        data = [[\"Sample\", \"Data\"], [\"Row1\", \"Value1\"], [\"Row2\", \"Value2\"]]\n",
        "        return Table(data, bbox, 0, 85.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHhtYF2Pyvp5"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# GRAPH DETECTION AND CLASSIFICATION\n",
        "# ============================================================================\n",
        "\n",
        "class GraphDetector(BaseDetector):\n",
        "    \"\"\"Detect and classify graphs/charts\"\"\"\n",
        "\n",
        "    def __init__(self, min_area: int = 5000):\n",
        "        self.min_area = min_area\n",
        "\n",
        "    def detect(self, page_image: np.ndarray, page_num: int) -> List[Tuple[BoundingBox, ElementType]]:\n",
        "        \"\"\"Detect graphs and return bbox with type\"\"\"\n",
        "        gray = cv2.cvtColor(page_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Detect colored/shaded regions (charts often have these)\n",
        "        hsv = cv2.cvtColor(page_image, cv2.COLOR_BGR2HSV)\n",
        "        mask = cv2.inRange(hsv, np.array([0, 30, 30]), np.array([180, 255, 255]))\n",
        "\n",
        "        # Find contours\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        results = []\n",
        "        for contour in contours:\n",
        "            area = cv2.contourArea(contour)\n",
        "            if area < self.min_area:\n",
        "                continue\n",
        "\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            bbox = BoundingBox(x, y, x+w, y+h)\n",
        "\n",
        "            # Extract region for classification\n",
        "            region = page_image[y:y+h, x:x+w]\n",
        "            graph_type = self._classify_graph(region, bbox)\n",
        "\n",
        "            results.append((bbox, graph_type))\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _classify_graph(self, image: np.ndarray, bbox: BoundingBox) -> ElementType:\n",
        "        \"\"\"Classify graph type using heuristics\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Check for circles (pie charts)\n",
        "        circles = cv2.HoughCircles(\n",
        "            gray, cv2.HOUGH_GRADIENT, dp=1, minDist=20,\n",
        "            param1=50, param2=30, minRadius=20, maxRadius=min(image.shape[:2])//2\n",
        "        )\n",
        "\n",
        "        if circles is not None and len(circles[0]) > 0:\n",
        "            return ElementType.PIE_CHART\n",
        "\n",
        "        # Check for bars (bar charts) - vertical rectangles\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "        contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        vertical_rects = 0\n",
        "        for cnt in contours:\n",
        "            x, y, w, h = cv2.boundingRect(cnt)\n",
        "            if h > w and h > 20:\n",
        "                vertical_rects += 1\n",
        "\n",
        "        if vertical_rects >= 3:\n",
        "            return ElementType.BAR_CHART\n",
        "\n",
        "        # Check for lines (line charts)\n",
        "        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50,\n",
        "                                minLineLength=30, maxLineGap=10)\n",
        "\n",
        "        if lines is not None and len(lines) > 5:\n",
        "            return ElementType.LINE_CHART\n",
        "\n",
        "        return ElementType.UNKNOWN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50XE1tbMsohr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple, Optional, Union\n",
        "from enum import Enum\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXTRACTION ENGINE\n",
        "# ============================================================================\n",
        "\n",
        "class TableGraphX:\n",
        "    \"\"\"\n",
        "    Main extraction engine - the public API\n",
        "    Usage: result = TableGraphX.extract('document.pdf', flavor='lattice')\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.detectors = {\n",
        "            'lattice': LineBasedTableDetector(),\n",
        "            'stream': TextClusterTableDetector(),\n",
        "            'ml': MLTableDetector()\n",
        "        }\n",
        "        self.parsers = {\n",
        "            'grid': GridBasedTableParser(),\n",
        "            'text': TextBasedTableParser()\n",
        "        }\n",
        "        self.graph_detector = GraphDetector()\n",
        "\n",
        "    @staticmethod\n",
        "    def extract(pdf_path: str,\n",
        "                pages: str = 'all',\n",
        "                flavor: str = 'lattice',\n",
        "                extract_graphs: bool = True,\n",
        "                parser: str = 'grid') -> ExtractionResult:\n",
        "        \"\"\"\n",
        "        Main extraction method\n",
        "\n",
        "        Args:\n",
        "            pdf_path: Path to PDF file\n",
        "            pages: Pages to extract ('all', '1', '1,2,3', '1-5')\n",
        "            flavor: Detection method ('lattice', 'stream', 'ml')\n",
        "            extract_graphs: Whether to extract graphs\n",
        "            parser: Parsing method ('grid', 'text')\n",
        "\n",
        "        Returns:\n",
        "            ExtractionResult containing tables and graphs\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Starting TableGraphX Extraction\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"PDF: {pdf_path}\")\n",
        "        print(f\"Flavor: {flavor}, Parser: {parser}, Extract Graphs: {extract_graphs}\")\n",
        "\n",
        "        engine = TableGraphX()\n",
        "        result = ExtractionResult(pdf_path)\n",
        "        doc = None\n",
        "\n",
        "        try:\n",
        "            # Open PDF\n",
        "            print(f\"\\n[1/4] Opening PDF...\")\n",
        "            doc = fitz.open(pdf_path)\n",
        "            result.n_pages = len(doc)\n",
        "            print(f\"      ✓ PDF opened successfully - {result.n_pages} pages found\")\n",
        "\n",
        "            pages_to_process = engine._parse_pages(pages, result.n_pages)\n",
        "            print(f\"\\n[2/4] Processing pages: {', '.join(str(p+1) for p in pages_to_process)}\")\n",
        "\n",
        "            table_detector = engine.detectors.get(flavor)\n",
        "            if not table_detector:\n",
        "                raise ValueError(f\"Unknown table detection flavor: {flavor}\")\n",
        "            table_parser = engine.parsers.get(parser)\n",
        "            if not table_parser:\n",
        "                raise ValueError(f\"Unknown table parser: {parser}\")\n",
        "\n",
        "            for page_num in pages_to_process:\n",
        "                page = doc.load_page(page_num)\n",
        "                # Render page to image at a higher DPI for better detection/OCR\n",
        "                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2)) # 2x resolution\n",
        "                page_image = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.h, pix.w, pix.n)\n",
        "                # Convert to BGR for OpenCV if necessary (PyMuPDF typically returns RGB or grayscale)\n",
        "                if pix.n == 3: # RGB\n",
        "                    page_image = cv2.cvtColor(page_image, cv2.COLOR_RGB2BGR)\n",
        "                elif pix.n == 4: # RGBA\n",
        "                    page_image = cv2.cvtColor(page_image, cv2.COLOR_RGBA2BGR)\n",
        "\n",
        "                # Scale factors for bounding box coordinates\n",
        "                scale_x = page.rect.width / pix.width\n",
        "                scale_y = page.rect.height / pix.height\n",
        "\n",
        "                # 3. Detect tables\n",
        "                print(f\"      > Detecting tables on page {page_num+1} using '{flavor}' flavor...\")\n",
        "                table_bboxes = table_detector.detect(page_image.copy(), page_num)\n",
        "                for bbox in table_bboxes:\n",
        "                    # Scale bbox back to original PDF coordinates if detector works on pixmap coords\n",
        "                    # (Assuming detector returns pixmap coords for now, adjust if it's PDF coords)\n",
        "                    scaled_bbox = BoundingBox(\n",
        "                        bbox.x1 * scale_x,\n",
        "                        bbox.y1 * scale_y,\n",
        "                        bbox.x2 * scale_x,\n",
        "                        bbox.y2 * scale_y\n",
        "                    )\n",
        "                    table_region_image = page_image[int(bbox.y1):int(bbox.y2), int(bbox.x1):int(bbox.x2)]\n",
        "                    if table_region_image.size > 0:\n",
        "                        table = table_parser.parse(table_region_image, scaled_bbox)\n",
        "                        table.page = page_num + 1\n",
        "                        result.tables.append(table)\n",
        "                print(f\"        Found {len(table_bboxes)} potential tables on page {page_num+1}\")\n",
        "\n",
        "                # 4. Detect and classify graphs\n",
        "                if extract_graphs:\n",
        "                    print(f\"      > Detecting graphs on page {page_num+1}...\")\n",
        "                    graph_detections = engine.graph_detector.detect(page_image.copy(), page_num)\n",
        "                    for bbox, graph_type in graph_detections:\n",
        "                        # Scale bbox back to original PDF coordinates\n",
        "                        scaled_bbox = BoundingBox(\n",
        "                            bbox.x1 * scale_x,\n",
        "                            bbox.y1 * scale_y,\n",
        "                            bbox.x2 * scale_x,\n",
        "                            bbox.y2 * scale_y\n",
        "                        )\n",
        "                        graph_image_region = page_image[int(bbox.y1):int(bbox.y2), int(bbox.x1):int(bbox.x2)]\n",
        "                        if graph_image_region.size > 0:\n",
        "                            graph = Graph(graph_image_region, scaled_bbox, page_num + 1, graph_type)\n",
        "                            result.graphs.append(graph)\n",
        "                    print(f\"        Found {len(graph_detections)} potential graphs on page {page_num+1}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during extraction: {e}\")\n",
        "            return None # Return None or raise an exception to indicate failure\n",
        "        finally:\n",
        "            if doc:\n",
        "                doc.close()\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Extraction complete.\")\n",
        "        print(f\"Total tables found: {len(result.tables)}\")\n",
        "        print(f\"Total graphs found: {len(result.graphs)}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _parse_pages(self, pages: str, total_pages: int) -> List[int]:\n",
        "        \"\"\"Parse page selection string\"\"\"\n",
        "        if pages == 'all':\n",
        "            return list(range(total_pages))\n",
        "\n",
        "        page_nums = []\n",
        "        parts = pages.split(',')\n",
        "\n",
        "        for part in parts:\n",
        "            if '-' in part:\n",
        "                start_str, end_str = part.split('-')\n",
        "                try:\n",
        "                    start = int(start_str)\n",
        "                    end = int(end_str)\n",
        "                    page_nums.extend(range(start - 1, end))\n",
        "                except ValueError:\n",
        "                    print(f\"Warning: Invalid page range format '{part}'. Skipping.\")\n",
        "            else:\n",
        "                try:\n",
        "                    page_num = int(part)\n",
        "                    page_nums.append(page_num - 1)\n",
        "                except ValueError:\n",
        "                    print(f\"Warning: Invalid page number format '{part}'. Skipping.\")\n",
        "\n",
        "        # Filter out invalid page numbers and remove duplicates\n",
        "        valid_page_nums = sorted(list(set([p for p in page_nums if 0 <= p < total_pages])))\n",
        "        return valid_page_nums\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CONVENIENCE FUNCTIONS (like camelot.read_pdf)\n",
        "# ============================================================================\n",
        "\n",
        "def read_pdf(filepath: str, **kwargs) -> ExtractionResult:\n",
        "    \"\"\"\n",
        "    Convenience function similar to camelot.read_pdf()\n",
        "\n",
        "    Example:\n",
        "        tables = read_pdf('document.pdf', pages='all', flavor='lattice')\n",
        "        print(f\"Found {len(tables.tables)} tables\")\n",
        "        tables.tables[0].to_csv('output.csv')\n",
        "    \"\"\"\n",
        "    return TableGraphX.extract(filepath, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXJNQuO6zFIy",
        "outputId": "d9745ac6-4151-41cd-c6de-0e7c8afe0674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Starting TableGraphX Extraction\n",
            "============================================================\n",
            "PDF: /content/image-to-text-13.pdf\n",
            "Flavor: lattice, Parser: grid, Extract Graphs: True\n",
            "\n",
            "[1/4] Opening PDF...\n",
            "      ✓ PDF opened successfully - 1 pages found\n",
            "\n",
            "[2/4] Processing pages: 1\n",
            "      > Detecting tables on page 1 using 'lattice' flavor...\n",
            "        Found 1 potential tables on page 1\n",
            "      > Detecting graphs on page 1...\n",
            "        Found 3 potential graphs on page 1\n",
            "\n",
            "============================================================\n",
            "Extraction complete.\n",
            "Total tables found: 1\n",
            "Total graphs found: 3\n",
            "============================================================\n",
            "Found 1 tables\n",
            "Found 3 graphs\n",
            "\n",
            "Table 1 (Page 1):\n",
            "  Shape: (241, 62)\n",
            "  Accuracy: 100.00%\n",
            "\n",
            "Graph 1 (Page 1):\n",
            "  Type: pie_chart\n",
            "  Confidence: 0.00\n",
            "\n",
            "Graph 2 (Page 1):\n",
            "  Type: line_chart\n",
            "  Confidence: 0.00\n",
            "\n",
            "Graph 3 (Page 1):\n",
            "  Type: unknown\n",
            "  Confidence: 0.00\n",
            "\n",
            "============================================================\n",
            "Starting TableGraphX Extraction\n",
            "============================================================\n",
            "PDF: /content/image-to-text-13.pdf\n",
            "Flavor: stream, Parser: grid, Extract Graphs: True\n",
            "\n",
            "[1/4] Opening PDF...\n",
            "      ✓ PDF opened successfully - 1 pages found\n",
            "\n",
            "[2/4] Processing pages: 1\n",
            "      > Detecting tables on page 1 using 'stream' flavor...\n",
            "        Found 1 potential tables on page 1\n",
            "      > Detecting graphs on page 1...\n",
            "        Found 3 potential graphs on page 1\n",
            "\n",
            "============================================================\n",
            "Extraction complete.\n",
            "Total tables found: 1\n",
            "Total graphs found: 3\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Starting TableGraphX Extraction\n",
            "============================================================\n",
            "PDF: /content/image-to-text-13.pdf\n",
            "Flavor: ml, Parser: grid, Extract Graphs: True\n",
            "\n",
            "[1/4] Opening PDF...\n",
            "      ✓ PDF opened successfully - 1 pages found\n",
            "\n",
            "[2/4] Processing pages: 1\n",
            "      > Detecting tables on page 1 using 'ml' flavor...\n",
            "        Found 0 potential tables on page 1\n",
            "      > Detecting graphs on page 1...\n",
            "        Found 3 potential graphs on page 1\n",
            "\n",
            "============================================================\n",
            "Extraction complete.\n",
            "Total tables found: 0\n",
            "Total graphs found: 3\n",
            "============================================================\n",
            "\n",
            "First table as DataFrame:\n",
            "                       ...                    \n",
            "0                      ...                    \n",
            "1                      ...                    \n",
            "2                      ...                    \n",
            "3                      ...                    \n",
            "4                      ...                    \n",
            "\n",
            "[5 rows x 62 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example 1: Extract tables (Camelot-style API)\n",
        "    result = read_pdf('/content/image-to-text-13.pdf', pages='all', flavor='lattice')\n",
        "\n",
        "    print(f\"Found {len(result.tables)} tables\")\n",
        "    print(f\"Found {len(result.graphs)} graphs\")\n",
        "\n",
        "    # Save tables\n",
        "    for i, table in enumerate(result.tables):\n",
        "        print(f\"\\nTable {i+1} (Page {table.page}):\")\n",
        "        print(f\"  Shape: {table.shape}\")\n",
        "        print(f\"  Accuracy: {table.accuracy:.2f}%\")\n",
        "        table.to_csv(f'table_{i+1}.csv')\n",
        "\n",
        "    # Save graphs\n",
        "    for i, graph in enumerate(result.graphs):\n",
        "        print(f\"\\nGraph {i+1} (Page {graph.page}):\")\n",
        "        print(f\"  Type: {graph.graph_type.value}\")\n",
        "        print(f\"  Confidence: {graph.confidence:.2f}\")\n",
        "        graph.save_image(f'graph_{i+1}.png')\n",
        "\n",
        "    # Example 2: Different detection methods\n",
        "    result_stream = read_pdf('/content/image-to-text-13.pdf', flavor='stream')\n",
        "    result_ml = read_pdf('/content/image-to-text-13.pdf', flavor='ml')\n",
        "\n",
        "    # Example 3: Filter by page\n",
        "    page_1_results = result.filter_by_page(1)\n",
        "\n",
        "    # Example 4: Access DataFrame directly\n",
        "    if result.tables:\n",
        "        df = result.tables[0].df\n",
        "        print(\"\\nFirst table as DataFrame:\")\n",
        "        print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr_Vfkc12NK4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}